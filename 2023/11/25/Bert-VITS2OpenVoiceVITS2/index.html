

<!DOCTYPE html>
<html lang="en" color-mode=light>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=no">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Bert-VITS2 - Avidya</title>
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="google" content="notranslate" />
  
  <meta name="description" content="IntroductionVITS2 proposed ...">
  <meta name="author" content="Kou">
  <link rel="icon" href="/images/icons/favicon-32x32.png" type="image/png" sizes="16x16">
  <link rel="icon" href="/images/icons/favicon-64x64.png" type="image/png" sizes="32x32">
  <link rel="apple-touch-icon" href="/images/icons/apple-touch-icon.png" sizes="180x180">
  <meta rel="mask-icon" href="/images/icons/stun-logo.svg" color="#333333">
  
    <meta rel="msapplication-TileImage" content="/images/icons/favicon-144x144.png">
    <meta rel="msapplication-TileColor" content="#000000">
  

  
<link rel="stylesheet" href="/css/style.css">


  
    
<link rel="stylesheet" href="https://at.alicdn.com/t/font_1445822_p6ry5n7lrr.css">

  

  
    
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css">

  

  
    
      
        
        
<link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.18.1/styles/foundation.min.css" name="highlight-style" mode="light">

      
        
        
<link rel="stylesheet" href="https://cdn.bootcss.com/highlight.js/9.18.1/styles/solarized-dark.min.css" name="highlight-style" mode="dark">

      
  

  <script>
    var CONFIG = window.CONFIG || {};
    var ZHAOO = window.ZHAOO || {};
    CONFIG = {
      isHome: false,
      fancybox: true,
      pjax: false,
      loading: {
        gif: '/images/theme/loading.gif',
        lottie: ''
      },
      lazyload: {
        enable: true,
        only_post: 'false',
        loading: {
          gif: '/images/theme/loading.gif',
          lottie: ''
        }
      },
      donate: {
        enable: false,
        alipay: '',
        wechat: ''
      },
      galleries: {
        enable: false
      },
      fab: {
        enable: true,
        always_show: false
      },
      carrier: {
        enable: true
      },
      daovoice: {
        enable: false
      },
      preview: {
        background: {
          default: '',
          api: ''
        },
        motto: {
          default: 'もしも僕が主人公なら、僕は人の心が見えて',
          typing: true,
          api: '',
          data_contents: '["data","content"]'
        },
      },
      qrcode: {
        enable: false,
        type: 'url',
        image: '/images/theme/qr-code.png',
      },
      toc: {
        enable: true
      },
      scrollbar: {
        type: 'default'
      },
      notification: {
        enable: false,
        delay: 4500,
        list: '',
        page_white_list: '',
        page_black_list: ''
      },
      search: {
        enable: false,
        path: ''
      }
    }
  </script>

  

  

<meta name="generator" content="Hexo 6.3.0"></head>

<body class="lock-screen">
  <div class="loading" id="loading"></div>
  
    


  <nav class="navbar">
    <div class="left">
      
        <i class="iconfont iconhome j-navbar-back-home"></i>
      
      
      
        <i class="iconfont iconmoono" id="color-toggle" color-toggle="light"></i>
      
      
    </div>
    <div class="center">Bert-VITS2</div>
    <div class="right">
      <i class="iconfont iconmenu j-navbar-menu"></i>
    </div>
    
  </nav>

  
  

<nav class="menu">
  <div class="menu-container">
    <div class="menu-close">
      <i class="iconfont iconbaseline-close-px"></i>
    </div>
    <ul class="menu-content"><li class="menu-item">
        <a href="/ " class="underline "> home</a>
      </li><li class="menu-item">
        <a href="/archives/ " class="underline "> archives</a>
      </li><li class="menu-item">
        <a href="/about/ " class="underline "> about</a>
      </li></ul>
    
  </div>
</nav>
  <main id="main">
  <div class="article-wrap">
    <div class="row container">
      <div class="col-xl-3"></div>
      <div class="col-xl-6"><article class="article">
  <div class="wrap">
    <section class="head">
  <img   class="lazyload" data-original="/images/theme/post-image.jpg" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="  draggable="false">
  <div class="head-mask">
    <h1 class="head-title">Bert-VITS2</h1>
    <div class="head-info">
      <span class="post-info-item"><i class="iconfont iconcalendar"></i>November 25, 2023</span>
      
      <span class="post-info-item"><i class="iconfont iconfont-size"></i>17518</span>
    </div>
  </div>
</section>
    <section class="main">
      <section class="content">
        
        <h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p><a target="_blank" rel="noopener" href="https://github.com/p0p4k/vits2_pytorch">VITS2</a> proposed an adversarially trained random duration predictor, which improves normalization flow by better modeling features of multiple speakers using Transformer blocks and a speaker-conditioned text encoder. The proposed approach enhances both quality and efficiency. Additionally, experiments using normalized text as input to the model reduce reliance on phoneme conversion. Consequently, these methods are closer to fully end-to-end single-stage approaches.<br><img   class="lazyload" data-original="/images%5Ctheme%5Cvits2.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg==" ></p>
<h1 id="Method"><a href="#Method" class="headerlink" title="Method"></a>Method</h1><p>There are four improvements based on VITS</p>
<h2 id="Stochastic-Duration-Predictor-with-Time-Step-wise-Conditional-Discriminator"><a href="#Stochastic-Duration-Predictor-with-Time-Step-wise-Conditional-Discriminator" class="headerlink" title="Stochastic Duration Predictor with Time Step-wise Conditional Discriminator"></a>Stochastic Duration Predictor with Time Step-wise Conditional Discriminator</h2><p><img    class="lazyload" data-original="/images%5Ctheme%5Cvits2-1.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption"> Training of the duration predictor</span></p>
<p>This picture shows the proposed duration predictor and discriminator trained using adversarial learning. The conditional discriminator is applied to distinguish the predicted duration appropriately from the input data of the generator.</p>
<p>The generator G takes the hidden representations of text (htext) and Gaussian noise <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="2.68ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 1153.7 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">Z_d</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-5A" d="M58 8Q58 23 64 35Q64 36 329 334T596 635L586 637Q575 637 512 637H500H476Q442 637 420 635T365 624T311 598T266 548T228 469Q227 466 226 463T224 458T223 453T222 450L221 448Q218 443 202 443Q185 443 182 453L214 561Q228 606 241 651Q249 679 253 681Q256 683 487 683H718Q723 678 723 675Q723 673 717 649Q189 54 188 52L185 49H274Q369 50 377 51Q452 60 500 100T579 247Q587 272 590 277T603 282H607Q628 282 628 271Q547 5 541 2Q538 0 300 0H124Q58 0 58 8Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-5A" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="966" y="-213"></use>
</g>
</svg> as inputs. MAS (Masked Attention for Selection) is utilized to obtain <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.465ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 1922.4 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">h_{text}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
<g transform="translate(576,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-65" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-78" x="828" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="1400" y="0"></use>
</g>
</g>
</svg> in a logarithmic scale.</p>
<p>The duration, either predicted from the logarithmic scale representation (<svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.216ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 523.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">d</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-64" x="0" y="0"></use>
</g>
</svg>) or from the duration predictor represented as <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="1.216ex" height="2.176ex" style="vertical-align: -0.338ex;" viewBox="0 -791.3 523.5 936.9" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">d</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-64" x="0" y="0"></use>
</g>
</svg>, is used as input for the discriminator D along with <svg xmlns:xlink="http://www.w3.org/1999/xlink" width="4.465ex" height="2.509ex" style="vertical-align: -0.671ex;" viewBox="0 -791.3 1922.4 1080.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">h_{text}</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMATHI-74" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z"></path>
<path stroke-width="1" id="E1-MJMATHI-65" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path>
<path stroke-width="1" id="E1-MJMATHI-78" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
<g transform="translate(576,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-65" x="361" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-78" x="828" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-74" x="1400" y="0"></use>
</g>
</g>
</svg> obtained from MAS. Typically, discriminators in generative adversarial networks are fed fixed-length inputs, whereas each token’s duration is predicted for variable-length inputs, and the input sequence length varies for each training instance. To properly distinguish variable-length inputs, the authors propose a timestep discriminator, which discriminates each predicted duration for all tokens.</p>
<p>Two types of losses are employed: a least squares loss function for adversarial learning and a mean squared error loss function.<br><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="100ex" height="18.509ex" style="vertical-align: -15.505ex; max-width: 60000px;" viewBox="0 -1293.7 43055.4 7969.2" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">L_{\text {adv }}(D)= \mathbb{E}_{\left(d, z_{d}, h_{\text {text }}\right)}\left[\left(D\left(d, h_{\text {text }}\right)-1\right)^{2}\right. \\\left.+\left(D\left(G\left(z_{d}, h_{\text {text }}\right), h_{\text {text }}\right)\right)^{2}\right], \\L_{\text {adv }}(G)= \mathbb{E}_{\left(z_{d}, h_{\text {text }}\right)}\left[\left(D\left(G\left(z_{d}, h_{\text {text }}\right)\right)-1\right)^{2}\right], \\L_{\text {mee }}= \operatorname{MSE}\left(G\left(z_{d}, h_{\text {text }}\right), d\right)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-4C" d="M228 637Q194 637 192 641Q191 643 191 649Q191 673 202 682Q204 683 217 683Q271 680 344 680Q485 680 506 683H518Q524 677 524 674T522 656Q517 641 513 637H475Q406 636 394 628Q387 624 380 600T313 336Q297 271 279 198T252 88L243 52Q243 48 252 48T311 46H328Q360 46 379 47T428 54T478 72T522 106T564 161Q580 191 594 228T611 270Q616 273 628 273H641Q647 264 647 262T627 203T583 83T557 9Q555 4 553 3T537 0T494 -1Q483 -1 418 -1T294 0H116Q32 0 32 10Q32 17 34 24Q39 43 44 45Q48 46 59 46H65Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Q285 635 228 637Z"></path>
<path stroke-width="1" id="E1-MJMAIN-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path>
<path stroke-width="1" id="E1-MJMAIN-64" d="M376 495Q376 511 376 535T377 568Q377 613 367 624T316 637H298V660Q298 683 300 683L310 684Q320 685 339 686T376 688Q393 689 413 690T443 693T454 694H457V390Q457 84 458 81Q461 61 472 55T517 46H535V0Q533 0 459 -5T380 -11H373V44L365 37Q307 -11 235 -11Q158 -11 96 50T34 215Q34 315 97 378T244 442Q319 442 376 393V495ZM373 342Q328 405 260 405Q211 405 173 369Q146 341 139 305T131 211Q131 155 138 120T173 59Q203 26 251 26Q322 26 373 103V342Z"></path>
<path stroke-width="1" id="E1-MJMAIN-76" d="M338 431Q344 429 422 429Q479 429 503 431H508V385H497Q439 381 423 345Q421 341 356 172T288 -2Q283 -11 263 -11Q244 -11 239 -2Q99 359 98 364Q93 378 82 381T43 385H19V431H25L33 430Q41 430 53 430T79 430T104 429T122 428Q217 428 232 431H240V385H226Q187 384 184 370Q184 366 235 234L286 102L377 341V349Q377 363 367 372T349 383T335 385H331V431H338Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-44" d="M287 628Q287 635 230 637Q207 637 200 638T193 647Q193 655 197 667T204 682Q206 683 403 683Q570 682 590 682T630 676Q702 659 752 597T803 431Q803 275 696 151T444 3L430 1L236 0H125H72Q48 0 41 2T33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM703 469Q703 507 692 537T666 584T629 613T590 629T555 636Q553 636 541 636T512 636T479 637H436Q392 637 386 627Q384 623 313 339T242 52Q242 48 253 48T330 47Q335 47 349 47T373 46Q499 46 581 128Q617 164 640 212T683 339T703 469Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJAMS-45" d="M12 666Q12 675 24 683H582Q590 680 593 672V588Q593 514 591 502T575 490Q567 490 563 495T555 517Q552 556 517 590Q486 623 445 634T340 648H282Q266 636 264 620T260 492V370H277Q329 375 358 391T404 439Q420 480 420 506Q420 529 436 529Q445 529 451 521Q455 517 455 361Q455 333 455 298T456 253Q456 217 453 207T437 197Q420 196 420 217Q420 240 406 270Q377 328 284 335H260V201Q261 174 261 134Q262 73 264 61T278 38Q281 36 282 35H331Q400 35 449 50Q571 93 602 179Q605 203 622 203Q629 203 634 197T640 183Q638 181 624 95T604 3L600 -1H24Q12 5 12 16Q12 35 51 35Q92 38 97 52Q102 60 102 341T97 632Q91 645 51 648Q12 648 12 666ZM137 341Q137 131 136 89T130 37Q129 36 129 35H235Q233 41 231 48L226 61V623L231 635L235 648H129Q132 641 133 638T135 603T137 517T137 341ZM557 603V648H504Q504 646 515 639Q527 634 542 619L557 603ZM420 317V397L406 383Q394 370 380 363L366 355Q373 350 382 346Q400 333 409 328L420 317ZM582 61L586 88Q585 88 582 83Q557 61 526 46L511 37L542 35H577Q577 36 578 39T580 49T582 61Z"></path>
<path stroke-width="1" id="E1-MJMATHI-64" d="M366 683Q367 683 438 688T511 694Q523 694 523 686Q523 679 450 384T375 83T374 68Q374 26 402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487H491Q506 153 506 145Q506 140 503 129Q490 79 473 48T445 8T417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157Q33 205 53 255T101 341Q148 398 195 420T280 442Q336 442 364 400Q369 394 369 396Q370 400 396 505T424 616Q424 629 417 632T378 637H357Q351 643 351 645T353 664Q358 683 366 683ZM352 326Q329 405 277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q233 26 290 98L298 109L352 326Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-7A" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path>
<path stroke-width="1" id="E1-MJMATHI-68" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path>
<path stroke-width="1" id="E1-MJMAIN-74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z"></path>
<path stroke-width="1" id="E1-MJMAIN-65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z"></path>
<path stroke-width="1" id="E1-MJMAIN-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5B" d="M118 -250V750H255V710H158V-210H255V-250H118Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E1-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E1-MJMAIN-32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path>
<path stroke-width="1" id="E1-MJSZ2-5B" d="M224 -649V1150H455V1099H275V-598H455V-649H224Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-47" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q492 659 471 656T418 643T357 615T294 567T236 496T189 394T158 260Q156 242 156 221Q156 173 170 136T206 79T256 45T308 28T353 24Q407 24 452 47T514 106Q517 114 529 161T541 214Q541 222 528 224T468 227H431Q425 233 425 235T427 254Q431 267 437 273H454Q494 271 594 271Q634 271 659 271T695 272T707 272Q721 272 721 263Q721 261 719 249Q714 230 709 228Q706 227 694 227Q674 227 653 224Q646 221 643 215T629 164Q620 131 614 108Q589 6 586 3Q584 1 581 1Q571 1 553 21T530 52Q530 53 528 52T522 47Q448 -22 322 -22Q201 -22 126 55T50 252Z"></path>
<path stroke-width="1" id="E1-MJMAIN-5D" d="M22 710V750H159V-250H22V-210H119V710H22Z"></path>
<path stroke-width="1" id="E1-MJSZ2-5D" d="M16 1099V1150H247V-649H16V-598H196V1099H16Z"></path>
<path stroke-width="1" id="E1-MJMAIN-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path>
<path stroke-width="1" id="E1-MJMAIN-4D" d="M132 622Q125 629 121 631T105 634T62 637H29V683H135Q221 683 232 682T249 675Q250 674 354 398L458 124L562 398Q666 674 668 675Q671 681 683 682T781 683H887V637H854Q814 636 803 634T785 622V61Q791 51 802 49T854 46H887V0H876Q855 3 736 3Q605 3 596 0H585V46H618Q660 47 669 49T688 61V347Q688 424 688 461T688 546T688 613L687 632Q454 14 450 7Q446 1 430 1T410 7Q409 9 292 316L176 624V606Q175 588 175 543T175 463T175 356L176 86Q187 50 261 46H278V0H269Q254 3 154 3Q52 3 37 0H29V46H46Q78 48 98 56T122 69T132 86V622Z"></path>
<path stroke-width="1" id="E1-MJMAIN-53" d="M55 507Q55 590 112 647T243 704H257Q342 704 405 641L426 672Q431 679 436 687T446 700L449 704Q450 704 453 704T459 705H463Q466 705 472 699V462L466 456H448Q437 456 435 459T430 479Q413 605 329 646Q292 662 254 662Q201 662 168 626T135 542Q135 508 152 480T200 435Q210 431 286 412T370 389Q427 367 463 314T500 191Q500 110 448 45T301 -21Q245 -21 201 -4T140 27L122 41Q118 36 107 21T87 -7T78 -21Q76 -22 68 -22H64Q61 -22 55 -16V101Q55 220 56 222Q58 227 76 227H89Q95 221 95 214Q95 182 105 151T139 90T205 42T305 24Q352 24 386 62T420 155Q420 198 398 233T340 281Q284 295 266 300Q261 301 239 306T206 314T174 325T141 343T112 367T85 402Q55 451 55 507Z"></path>
<path stroke-width="1" id="E1-MJMAIN-45" d="M128 619Q121 626 117 628T101 631T58 634H25V680H597V676Q599 670 611 560T625 444V440H585V444Q584 447 582 465Q578 500 570 526T553 571T528 601T498 619T457 629T411 633T353 634Q266 634 251 633T233 622Q233 622 233 621Q232 619 232 497V376H286Q359 378 377 385Q413 401 416 469Q416 471 416 473V493H456V213H416V233Q415 268 408 288T383 317T349 328T297 330Q290 330 286 330H232V196V114Q232 57 237 52Q243 47 289 47H340H391Q428 47 452 50T505 62T552 92T584 146Q594 172 599 200T607 247T612 270V273H652V270Q651 267 632 137T610 3V0H25V46H58Q100 47 109 49T128 61V619Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
<g transform="translate(12470,0)">
 <use xlink:href="#E1-MJMATHI-4C" x="0" y="0"></use>
<g transform="translate(681,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-61"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-64" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-76" x="1057" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-28" x="2152" y="0"></use>
 <use xlink:href="#E1-MJMATHI-44" x="2542" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="3370" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="4037" y="0"></use>
<g transform="translate(5094,0)">
 <use xlink:href="#E1-MJAMS-45" x="0" y="0"></use>
<g transform="translate(667,-187)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="389" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2C" x="913" y="0"></use>
<g transform="translate(842,0)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-7A" x="0" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMATHI-64" x="573" y="-271"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2C" x="2182" y="0"></use>
<g transform="translate(1739,0)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
<g transform="translate(407,-111)">
 <use transform="scale(0.574)" xlink:href="#E1-MJMAIN-74"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMAIN-65" x="389" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMAIN-78" x="834" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMAIN-74" x="1362" y="0"></use>
</g>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-29" x="4912" y="0"></use>
</g>
</g>
<g transform="translate(9777,0)">
 <use xlink:href="#E1-MJSZ2-5B"></use>
<g transform="translate(472,0)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-44" x="389" y="0"></use>
<g transform="translate(1384,0)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="389" y="0"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="913" y="0"></use>
<g transform="translate(1358,0)">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
<g transform="translate(576,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-74"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-65" x="389" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-78" x="833" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-74" x="1362" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="3523" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2212" x="5519" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="6520" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="7021" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="10480" y="675"></use>
</g>
</g>
</g>
<g transform="translate(15148,-2232)">
 <use xlink:href="#E1-MJMAIN-2B" x="0" y="0"></use>
<g transform="translate(778,0)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-44" x="389" y="0"></use>
<g transform="translate(1384,0)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-47" x="389" y="0"></use>
<g transform="translate(1342,0)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
<g transform="translate(389,0)">
 <use xlink:href="#E1-MJMATHI-7A" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="658" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="1325" y="0"></use>
<g transform="translate(1770,0)">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
<g transform="translate(576,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-74"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-65" x="389" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-78" x="833" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-74" x="1362" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="3935" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="5834" y="0"></use>
<g transform="translate(6279,0)">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
<g transform="translate(576,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-74"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-65" x="389" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-78" x="833" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-74" x="1362" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="8445" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="10219" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="15002" y="675"></use>
</g>
 <use xlink:href="#E1-MJSZ2-5D" x="11841" y="-1"></use>
 <use xlink:href="#E1-MJMAIN-2C" x="12480" y="0"></use>
</g>
<g transform="translate(11243,-4464)">
 <use xlink:href="#E1-MJMATHI-4C" x="0" y="0"></use>
<g transform="translate(681,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-61"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-64" x="500" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-76" x="1057" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-28" x="2152" y="0"></use>
 <use xlink:href="#E1-MJMATHI-47" x="2542" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="3328" y="0"></use>
 <use xlink:href="#E1-MJMAIN-3D" x="3995" y="0"></use>
<g transform="translate(5052,0)">
 <use xlink:href="#E1-MJAMS-45" x="0" y="0"></use>
<g transform="translate(667,-187)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
<g transform="translate(275,0)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-7A" x="0" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMATHI-64" x="573" y="-271"></use>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2C" x="1380" y="0"></use>
<g transform="translate(1172,0)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
<g transform="translate(407,-111)">
 <use transform="scale(0.574)" xlink:href="#E1-MJMAIN-74"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMAIN-65" x="389" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMAIN-78" x="834" y="0"></use>
 <use transform="scale(0.574)" xlink:href="#E1-MJMAIN-74" x="1362" y="0"></use>
</g>
</g>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-29" x="4110" y="0"></use>
</g>
</g>
<g transform="translate(9168,0)">
 <use xlink:href="#E1-MJSZ2-5B"></use>
<g transform="translate(472,0)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-44" x="389" y="0"></use>
<g transform="translate(1384,0)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-47" x="389" y="0"></use>
<g transform="translate(1342,0)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
<g transform="translate(389,0)">
 <use xlink:href="#E1-MJMATHI-7A" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="658" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="1325" y="0"></use>
<g transform="translate(1770,0)">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
<g transform="translate(576,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-74"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-65" x="389" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-78" x="833" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-74" x="1362" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="3935" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="5667" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2212" x="7664" y="0"></use>
 <use xlink:href="#E1-MJMAIN-31" x="8664" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="9165" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-32" x="13512" y="675"></use>
</g>
 <use xlink:href="#E1-MJSZ2-5D" x="10481" y="-1"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="20289" y="0"></use>
</g>
<g transform="translate(15061,-6296)">
 <use xlink:href="#E1-MJMATHI-4C" x="0" y="0"></use>
<g transform="translate(681,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-6D"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-65" x="833" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-65" x="1278" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-3D" x="2527" y="0"></use>
<g transform="translate(3583,0)">
 <use xlink:href="#E1-MJMAIN-4D"></use>
 <use xlink:href="#E1-MJMAIN-53" x="917" y="0"></use>
 <use xlink:href="#E1-MJMAIN-45" x="1474" y="0"></use>
</g>
<g transform="translate(5739,0)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
 <use xlink:href="#E1-MJMATHI-47" x="389" y="0"></use>
<g transform="translate(1342,0)">
 <use xlink:href="#E1-MJMAIN-28" x="0" y="0"></use>
<g transform="translate(389,0)">
 <use xlink:href="#E1-MJMATHI-7A" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-64" x="658" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="1325" y="0"></use>
<g transform="translate(1770,0)">
 <use xlink:href="#E1-MJMATHI-68" x="0" y="0"></use>
<g transform="translate(576,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-74"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-65" x="389" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-78" x="833" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-74" x="1362" y="0"></use>
</g>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="3935" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="5834" y="0"></use>
 <use xlink:href="#E1-MJMATHI-64" x="6279" y="0"></use>
 <use xlink:href="#E1-MJMAIN-29" x="6803" y="0"></use>
</g>
</g>
</g>
</svg><br>The proposed duration predictor and training mechanism enable learning of durations in short steps, and the duration predictor is separately trained as the final training step, reducing the overall computational time for training.</p>
<h2 id="Monotonic-Alignment-Search-with-Gaussian-Noise"><a href="#Monotonic-Alignment-Search-with-Gaussian-Noise" class="headerlink" title="Monotonic Alignment Search with Gaussian Noise"></a>Monotonic Alignment Search with Gaussian Noise</h2><p>MAS (Masked Attention for Selection) is introduced into the model to learn alignment. The algorithm generates alignments between text and audio with the highest probability among all possible monotonic alignments, and trains the model to maximize their probability. This method is effective; however, exploration for more suitable alignments is limited after searching and optimizing specific alignments. To alleviate this situation, a small Gaussian noise is added to the computed probabilities. This provides the model with additional opportunities to search for alternative alignments. This noise is only added at the beginning of training because MAS enables the model to quickly learn alignments. Referring to previous work, which describes the algorithm in detail, Q-values are calculated as the maximum log likelihood over all possible positions for positive operations. A small Gaussian noise is added to the computed Q-values during operation.<br><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="21.709ex" height="3.176ex" style="vertical-align: -1.005ex;" viewBox="0 -934.9 9346.8 1367.4" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">P_{i, j} = \log \mathcal{N}\left(z_{j} \mu_{i}, \sigma_{i}\right)</title>
<defs aria-hidden="true">
<path stroke-width="1" id="E1-MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path>
<path stroke-width="1" id="E1-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E1-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E1-MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path>
<path stroke-width="1" id="E1-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E1-MJMAIN-6C" d="M42 46H56Q95 46 103 60V68Q103 77 103 91T103 124T104 167T104 217T104 272T104 329Q104 366 104 407T104 482T104 542T103 586T103 603Q100 622 89 628T44 637H26V660Q26 683 28 683L38 684Q48 685 67 686T104 688Q121 689 141 690T171 693T182 694H185V379Q185 62 186 60Q190 52 198 49Q219 46 247 46H263V0H255L232 1Q209 2 183 2T145 3T107 3T57 1L34 0H26V46H42Z"></path>
<path stroke-width="1" id="E1-MJMAIN-6F" d="M28 214Q28 309 93 378T250 448Q340 448 405 380T471 215Q471 120 407 55T250 -10Q153 -10 91 57T28 214ZM250 30Q372 30 372 193V225V250Q372 272 371 288T364 326T348 362T317 390T268 410Q263 411 252 411Q222 411 195 399Q152 377 139 338T126 246V226Q126 130 145 91Q177 30 250 30Z"></path>
<path stroke-width="1" id="E1-MJMAIN-67" d="M329 409Q373 453 429 453Q459 453 472 434T485 396Q485 382 476 371T449 360Q416 360 412 390Q410 404 415 411Q415 412 416 414V415Q388 412 363 393Q355 388 355 386Q355 385 359 381T368 369T379 351T388 325T392 292Q392 230 343 187T222 143Q172 143 123 171Q112 153 112 133Q112 98 138 81Q147 75 155 75T227 73Q311 72 335 67Q396 58 431 26Q470 -13 470 -72Q470 -139 392 -175Q332 -206 250 -206Q167 -206 107 -175Q29 -140 29 -75Q29 -39 50 -15T92 18L103 24Q67 55 67 108Q67 155 96 193Q52 237 52 292Q52 355 102 398T223 442Q274 442 318 416L329 409ZM299 343Q294 371 273 387T221 404Q192 404 171 388T145 343Q142 326 142 292Q142 248 149 227T179 192Q196 182 222 182Q244 182 260 189T283 207T294 227T299 242Q302 258 302 292T299 343ZM403 -75Q403 -50 389 -34T348 -11T299 -2T245 0H218Q151 0 138 -6Q118 -15 107 -34T95 -74Q95 -84 101 -97T122 -127T170 -155T250 -167Q319 -167 361 -139T403 -75Z"></path>
<path stroke-width="1" id="E1-MJCAL-4E" d="M343 705Q358 705 358 698Q360 696 370 658T411 524T484 319Q536 174 590 82L595 73L615 152Q646 274 683 407Q729 571 752 637T799 727Q852 780 937 788Q939 788 947 788T958 789H962Q979 789 979 765Q979 722 951 692Q942 683 924 683Q888 681 859 672T818 654T803 639Q784 608 708 322T631 15Q631 14 630 15Q630 17 629 15Q628 14 628 12Q621 -4 601 -17T560 -31Q550 -31 546 -28T530 -7Q484 67 458 123T398 272Q352 392 314 514L306 535V534Q306 533 296 488T272 379T234 239T185 100T127 -7T61 -50Q34 -50 4 -34T-27 8Q-27 33 -12 61T18 90Q21 90 36 77T87 57H92Q109 57 123 78T162 173Q206 299 232 417T265 599T276 667Q284 681 304 693T343 705Z"></path>
<path stroke-width="1" id="E1-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E1-MJMATHI-7A" d="M347 338Q337 338 294 349T231 360Q211 360 197 356T174 346T162 335T155 324L153 320Q150 317 138 317Q117 317 117 325Q117 330 120 339Q133 378 163 406T229 440Q241 442 246 442Q271 442 291 425T329 392T367 375Q389 375 411 408T434 441Q435 442 449 442H462Q468 436 468 434Q468 430 463 420T449 399T432 377T418 358L411 349Q368 298 275 214T160 106L148 94L163 93Q185 93 227 82T290 71Q328 71 360 90T402 140Q406 149 409 151T424 153Q443 153 443 143Q443 138 442 134Q425 72 376 31T278 -11Q252 -11 232 6T193 40T155 57Q111 57 76 -3Q70 -11 59 -11H54H41Q35 -5 35 -2Q35 13 93 84Q132 129 225 214T340 322Q352 338 347 338Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3BC" d="M58 -216Q44 -216 34 -208T23 -186Q23 -176 96 116T173 414Q186 442 219 442Q231 441 239 435T249 423T251 413Q251 401 220 279T187 142Q185 131 185 107V99Q185 26 252 26Q261 26 270 27T287 31T302 38T315 45T327 55T338 65T348 77T356 88T365 100L372 110L408 253Q444 395 448 404Q461 431 491 431Q504 431 512 424T523 412T525 402L449 84Q448 79 448 68Q448 43 455 35T476 26Q485 27 496 35Q517 55 537 131Q543 151 547 152Q549 153 557 153H561Q580 153 580 144Q580 138 575 117T555 63T523 13Q510 0 491 -8Q483 -10 467 -10Q446 -10 429 -4T402 11T385 29T376 44T374 51L368 45Q362 39 350 30T324 12T288 -4T246 -11Q199 -11 153 12L129 -85Q108 -167 104 -180T92 -202Q76 -216 58 -216Z"></path>
<path stroke-width="1" id="E1-MJMATHI-3C3" d="M184 -11Q116 -11 74 34T31 147Q31 247 104 333T274 430Q275 431 414 431H552Q553 430 555 429T559 427T562 425T565 422T567 420T569 416T570 412T571 407T572 401Q572 357 507 357Q500 357 490 357T476 358H416L421 348Q439 310 439 263Q439 153 359 71T184 -11ZM361 278Q361 358 276 358Q152 358 115 184Q114 180 114 178Q106 141 106 117Q106 67 131 47T188 26Q242 26 287 73Q316 103 334 153T356 233T361 278Z"></path>
<path stroke-width="1" id="E1-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E1-MJMATHI-50" x="0" y="0"></use>
<g transform="translate(642,-150)">
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMAIN-2C" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="624" y="0"></use>
</g>
 <use xlink:href="#E1-MJMAIN-3D" x="1753" y="0"></use>
<g transform="translate(2809,0)">
 <use xlink:href="#E1-MJMAIN-6C"></use>
 <use xlink:href="#E1-MJMAIN-6F" x="278" y="0"></use>
 <use xlink:href="#E1-MJMAIN-67" x="779" y="0"></use>
</g>
 <use xlink:href="#E1-MJCAL-4E" x="4255" y="0"></use>
<g transform="translate(5401,0)">
 <use xlink:href="#E1-MJMAIN-28"></use>
<g transform="translate(389,0)">
 <use xlink:href="#E1-MJMATHI-7A" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-6A" x="658" y="-213"></use>
</g>
<g transform="translate(1246,0)">
 <use xlink:href="#E1-MJMATHI-3BC" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="853" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-2C" x="2194" y="0"></use>
<g transform="translate(2639,0)">
 <use xlink:href="#E1-MJMATHI-3C3" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E1-MJMATHI-69" x="808" y="-213"></use>
</g>
 <use xlink:href="#E1-MJMAIN-29" x="3555" y="0"></use>
</g>
</g>
</svg><br><svg xmlns:xlink="http://www.w3.org/1999/xlink" width="38.326ex" height="3.009ex" style="vertical-align: -1.005ex;" viewBox="0 -863.1 16501.6 1295.7" role="img" focusable="false" xmlns="http://www.w3.org/2000/svg" aria-labelledby="MathJax-SVG-1-Title">
<title id="MathJax-SVG-1-Title">Q_{i,j} = \max \left(Q_{i-1, j-1}, Q_{i, j-1}\right)+P_{i, j}+\epsilon </title>
<defs aria-hidden="true">
<path stroke-width="1" id="E2-MJMATHI-51" d="M399 -80Q399 -47 400 -30T402 -11V-7L387 -11Q341 -22 303 -22Q208 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435Q740 255 592 107Q529 47 461 16L444 8V3Q444 2 449 -24T470 -66T516 -82Q551 -82 583 -60T625 -3Q631 11 638 11Q647 11 649 2Q649 -6 639 -34T611 -100T557 -165T481 -194Q399 -194 399 -87V-80ZM636 468Q636 523 621 564T580 625T530 655T477 665Q429 665 379 640Q277 591 215 464T153 216Q153 110 207 59Q231 38 236 38V46Q236 86 269 120T347 155Q372 155 390 144T417 114T429 82T435 55L448 64Q512 108 557 185T619 334T636 468ZM314 18Q362 18 404 39L403 49Q399 104 366 115Q354 117 347 117Q344 117 341 117T337 118Q317 118 296 98T274 52Q274 18 314 18Z"></path>
<path stroke-width="1" id="E2-MJMATHI-69" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z"></path>
<path stroke-width="1" id="E2-MJMAIN-2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path>
<path stroke-width="1" id="E2-MJMATHI-6A" d="M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z"></path>
<path stroke-width="1" id="E2-MJMAIN-3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path>
<path stroke-width="1" id="E2-MJMAIN-6D" d="M41 46H55Q94 46 102 60V68Q102 77 102 91T102 122T103 161T103 203Q103 234 103 269T102 328V351Q99 370 88 376T43 385H25V408Q25 431 27 431L37 432Q47 433 65 434T102 436Q119 437 138 438T167 441T178 442H181V402Q181 364 182 364T187 369T199 384T218 402T247 421T285 437Q305 442 336 442Q351 442 364 440T387 434T406 426T421 417T432 406T441 395T448 384T452 374T455 366L457 361L460 365Q463 369 466 373T475 384T488 397T503 410T523 422T546 432T572 439T603 442Q729 442 740 329Q741 322 741 190V104Q741 66 743 59T754 49Q775 46 803 46H819V0H811L788 1Q764 2 737 2T699 3Q596 3 587 0H579V46H595Q656 46 656 62Q657 64 657 200Q656 335 655 343Q649 371 635 385T611 402T585 404Q540 404 506 370Q479 343 472 315T464 232V168V108Q464 78 465 68T468 55T477 49Q498 46 526 46H542V0H534L510 1Q487 2 460 2T422 3Q319 3 310 0H302V46H318Q379 46 379 62Q380 64 380 200Q379 335 378 343Q372 371 358 385T334 402T308 404Q263 404 229 370Q202 343 195 315T187 232V168V108Q187 78 188 68T191 55T200 49Q221 46 249 46H265V0H257L234 1Q210 2 183 2T145 3Q42 3 33 0H25V46H41Z"></path>
<path stroke-width="1" id="E2-MJMAIN-61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z"></path>
<path stroke-width="1" id="E2-MJMAIN-78" d="M201 0Q189 3 102 3Q26 3 17 0H11V46H25Q48 47 67 52T96 61T121 78T139 96T160 122T180 150L226 210L168 288Q159 301 149 315T133 336T122 351T113 363T107 370T100 376T94 379T88 381T80 383Q74 383 44 385H16V431H23Q59 429 126 429Q219 429 229 431H237V385Q201 381 201 369Q201 367 211 353T239 315T268 274L272 270L297 304Q329 345 329 358Q329 364 327 369T322 376T317 380T310 384L307 385H302V431H309Q324 428 408 428Q487 428 493 431H499V385H492Q443 385 411 368Q394 360 377 341T312 257L296 236L358 151Q424 61 429 57T446 50Q464 46 499 46H516V0H510H502Q494 1 482 1T457 2T432 2T414 3Q403 3 377 3T327 1L304 0H295V46H298Q309 46 320 51T331 63Q331 65 291 120L250 175Q249 174 219 133T185 88Q181 83 181 74Q181 63 188 55T206 46Q208 46 208 23V0H201Z"></path>
<path stroke-width="1" id="E2-MJMAIN-28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path>
<path stroke-width="1" id="E2-MJMAIN-2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path>
<path stroke-width="1" id="E2-MJMAIN-31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path>
<path stroke-width="1" id="E2-MJMAIN-29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path>
<path stroke-width="1" id="E2-MJMAIN-2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path>
<path stroke-width="1" id="E2-MJMATHI-50" d="M287 628Q287 635 230 637Q206 637 199 638T192 648Q192 649 194 659Q200 679 203 681T397 683Q587 682 600 680Q664 669 707 631T751 530Q751 453 685 389Q616 321 507 303Q500 302 402 301H307L277 182Q247 66 247 59Q247 55 248 54T255 50T272 48T305 46H336Q342 37 342 35Q342 19 335 5Q330 0 319 0Q316 0 282 1T182 2Q120 2 87 2T51 1Q33 1 33 11Q33 13 36 25Q40 41 44 43T67 46Q94 46 127 49Q141 52 146 61Q149 65 218 339T287 628ZM645 554Q645 567 643 575T634 597T609 619T560 635Q553 636 480 637Q463 637 445 637T416 636T404 636Q391 635 386 627Q384 621 367 550T332 412T314 344Q314 342 395 342H407H430Q542 342 590 392Q617 419 631 471T645 554Z"></path>
<path stroke-width="1" id="E2-MJMATHI-3F5" d="M227 -11Q149 -11 95 41T40 174Q40 262 87 322Q121 367 173 396T287 430Q289 431 329 431H367Q382 426 382 411Q382 385 341 385H325H312Q191 385 154 277L150 265H327Q340 256 340 246Q340 228 320 219H138V217Q128 187 128 143Q128 77 160 52T231 26Q258 26 284 36T326 57T343 68Q350 68 354 58T358 39Q358 36 357 35Q354 31 337 21T289 0T227 -11Z"></path>
</defs>
<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="matrix(1 0 0 -1 0 0)" aria-hidden="true">
 <use xlink:href="#E2-MJMATHI-51" x="0" y="0"></use>
<g transform="translate(791,-150)">
 <use transform="scale(0.707)" xlink:href="#E2-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMAIN-2C" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMATHI-6A" x="624" y="0"></use>
</g>
 <use xlink:href="#E2-MJMAIN-3D" x="1902" y="0"></use>
<g transform="translate(2958,0)">
 <use xlink:href="#E2-MJMAIN-6D"></use>
 <use xlink:href="#E2-MJMAIN-61" x="833" y="0"></use>
 <use xlink:href="#E2-MJMAIN-78" x="1334" y="0"></use>
</g>
<g transform="translate(4987,0)">
 <use xlink:href="#E2-MJMAIN-28"></use>
<g transform="translate(389,0)">
 <use xlink:href="#E2-MJMATHI-51" x="0" y="0"></use>
<g transform="translate(791,-150)">
 <use transform="scale(0.707)" xlink:href="#E2-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMAIN-2212" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMAIN-31" x="1124" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMAIN-2C" x="1624" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMATHI-6A" x="1903" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMAIN-2212" x="2315" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMAIN-31" x="3094" y="0"></use>
</g>
</g>
 <use xlink:href="#E2-MJMAIN-2C" x="3822" y="0"></use>
<g transform="translate(4267,0)">
 <use xlink:href="#E2-MJMATHI-51" x="0" y="0"></use>
<g transform="translate(791,-150)">
 <use transform="scale(0.707)" xlink:href="#E2-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMAIN-2C" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMATHI-6A" x="624" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMAIN-2212" x="1036" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMAIN-31" x="1815" y="0"></use>
</g>
</g>
 <use xlink:href="#E2-MJMAIN-29" x="6796" y="0"></use>
</g>
 <use xlink:href="#E2-MJMAIN-2B" x="12396" y="0"></use>
<g transform="translate(13396,0)">
 <use xlink:href="#E2-MJMATHI-50" x="0" y="0"></use>
<g transform="translate(642,-150)">
 <use transform="scale(0.707)" xlink:href="#E2-MJMATHI-69" x="0" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMAIN-2C" x="345" y="0"></use>
 <use transform="scale(0.707)" xlink:href="#E2-MJMATHI-6A" x="624" y="0"></use>
</g>
</g>
 <use xlink:href="#E2-MJMAIN-2B" x="15094" y="0"></use>
 <use xlink:href="#E2-MJMATHI-3F5" x="16095" y="0"></use>
</g>
</svg></p>
<h2 id="Normalizing-Flows-using-Transformer-Block"><a href="#Normalizing-Flows-using-Transformer-Block" class="headerlink" title="Normalizing Flows using Transformer Block"></a>Normalizing Flows using Transformer Block</h2><p>Previous work has demonstrated the ability of variational autoencoders enhanced with normalization flows to synthesize high-quality speech audio. Normalization flows include convolutional blocks, which are effective structures for capturing patterns in adjacent data and enabling the model to synthesize high-quality speech. When transforming distributions, the ability to capture long-term dependencies is crucial because each part of speech is correlated with non-adjacent parts. While convolutional blocks effectively capture adjacent patterns, they have limitations in capturing long-term dependencies due to their limited receptive field.</p>
<p>Therefore, a small Transformer block with residual connections is added to the normalization flow to capture long-term dependencies.<br><img    class="lazyload" data-original="/images%5Ctheme%5Cvits2-2.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption"> Training of the duration predictor</span></p>
<h2 id="Speaker-Conditioned-Text-Encoder"><a href="#Speaker-Conditioned-Text-Encoder" class="headerlink" title="Speaker-Conditioned Text Encoder"></a>Speaker-Conditioned Text Encoder</h2><p>Since a multi-speaker model synthesizes speech with various characteristics based on speaker conditioning using a single model, expressing individual speech characteristics for each speaker is an important quality factor as well as naturalness. Previous work has shown that single-stage models can effectively model multiple speakers with high quality. Considering that certain features such as specific pronunciation and intonation significantly affect the expression of each speaker’s speech characteristics but are not included in the input text, a text encoder conditioned on speaker information is designed to better emulate various speech characteristics of each speaker by learning features while encoding the input text. The speaker vector is adjusted on the third Transformer block of the text encoder.<br><img    class="lazyload" data-original="/images%5Ctheme%5Cvits2-3.png" src="data:image/gif;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVQImWNgYGBgAAAABQABh6FO1AAAAABJRU5ErkJggg=="   ><span class="image-caption"> Training of the duration predictor</span></p>
<h1 id="Bert-VITS2"><a href="#Bert-VITS2" class="headerlink" title="Bert-VITS2"></a>Bert-VITS2</h1><p><a target="_blank" rel="noopener" href="https://github.com/fishaudio/Bert-VITS2">https://github.com/fishaudio/Bert-VITS2</a><br>Its idea is to introduce Bert to VITS2 to improve the performance on tone</p>
<h2 id="Segmentation"><a href="#Segmentation" class="headerlink" title="Segmentation"></a>Segmentation</h2><p>Using the g2p module, segment the text into sentences and convert them into phones (phonetic representations), tones (intonations), and word-to-phoneme mappings (word2ph).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">g2p</span>(<span class="hljs-params">text</span>):<br>    phones = []<br>    tones = []<br>    phone_len = []<br>    <span class="hljs-comment"># words = sep_text(text)</span><br>    <span class="hljs-comment"># tokens = [tokenizer.tokenize(i) for i in words]</span><br>    words = text_to_words(text)<br><br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>        temp_phones, temp_tones = [], []<br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(word) &gt; <span class="hljs-number">1</span>:<br>            <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;&#x27;&quot;</span> <span class="hljs-keyword">in</span> word:<br>                word = [<span class="hljs-string">&quot;&quot;</span>.join(word)]<br>        <span class="hljs-keyword">for</span> w <span class="hljs-keyword">in</span> word:<br>            <span class="hljs-keyword">if</span> w <span class="hljs-keyword">in</span> punctuation:<br>                temp_phones.append(w)<br>                temp_tones.append(<span class="hljs-number">0</span>)<br>                <span class="hljs-keyword">continue</span><br>            <span class="hljs-keyword">if</span> w.upper() <span class="hljs-keyword">in</span> eng_dict:<br>                phns, tns = refine_syllables(eng_dict[w.upper()])<br>                temp_phones += [post_replace_ph(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> phns]<br>                temp_tones += tns<br>                <span class="hljs-comment"># w2ph.append(len(phns))</span><br>            <span class="hljs-keyword">else</span>:<br>                phone_list = <span class="hljs-built_in">list</span>(<span class="hljs-built_in">filter</span>(<span class="hljs-keyword">lambda</span> p: p != <span class="hljs-string">&quot; &quot;</span>, _g2p(w)))<br>                phns = []<br>                tns = []<br>                <span class="hljs-keyword">for</span> ph <span class="hljs-keyword">in</span> phone_list:<br>                    <span class="hljs-keyword">if</span> ph <span class="hljs-keyword">in</span> arpa:<br>                        ph, tn = refine_ph(ph)<br>                        phns.append(ph)<br>                        tns.append(tn)<br>                    <span class="hljs-keyword">else</span>:<br>                        phns.append(ph)<br>                        tns.append(<span class="hljs-number">0</span>)<br>                temp_phones += [post_replace_ph(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> phns]<br>                temp_tones += tns<br>        phones += temp_phones<br>        tones += temp_tones<br>        phone_len.append(<span class="hljs-built_in">len</span>(temp_phones))<br>        <span class="hljs-comment"># phones = [post_replace_ph(i) for i in phones]</span><br><br>    word2ph = []<br>    <span class="hljs-keyword">for</span> token, pl <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(words, phone_len):<br>        word_len = <span class="hljs-built_in">len</span>(token)<br><br>        aaa = distribute_phone(pl, word_len)<br>        word2ph += aaa<br><br>    phones = [<span class="hljs-string">&quot;_&quot;</span>] + phones + [<span class="hljs-string">&quot;_&quot;</span>]<br>    tones = [<span class="hljs-number">0</span>] + tones + [<span class="hljs-number">0</span>]<br>    word2ph = [<span class="hljs-number">1</span>] + word2ph + [<span class="hljs-number">1</span>]<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(phones) == <span class="hljs-built_in">len</span>(tones), text<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(phones) == <span class="hljs-built_in">sum</span>(word2ph), text<br><br>    <span class="hljs-keyword">return</span> phones, tones, word2ph<br></code></pre></td></tr></table></figure>
<h2 id="Tone-encoding"><a href="#Tone-encoding" class="headerlink" title="Tone encoding"></a>Tone encoding</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">clean_text_bert</span>(<span class="hljs-params">text, language</span>):<br>    language_module = language_module_map[language]<br>    norm_text = language_module.text_normalize(text)<br>    phones, tones, word2ph = language_module.g2p(norm_text)<br>    bert = language_module.get_bert_feature(norm_text, word2ph)<br>    <span class="hljs-keyword">return</span> phones, tones, bert<br></code></pre></td></tr></table></figure>

<h2 id="Extracting-BERT-features-from-text-data"><a href="#Extracting-BERT-features-from-text-data" class="headerlink" title="Extracting BERT features from text data"></a>Extracting BERT features from text data</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">def</span> <span class="hljs-title function_">get_bert_feature</span>(<span class="hljs-params"></span><br><span class="hljs-params">    text,</span><br><span class="hljs-params">    word2ph,</span><br><span class="hljs-params">    device=config.bert_gen_config.device,</span><br><span class="hljs-params">    style_text=<span class="hljs-literal">None</span>,</span><br><span class="hljs-params">    style_weight=<span class="hljs-number">0.7</span>,</span><br><span class="hljs-params"></span>):<br>    <span class="hljs-keyword">if</span> (<br>        sys.platform == <span class="hljs-string">&quot;darwin&quot;</span><br>        <span class="hljs-keyword">and</span> torch.backends.mps.is_available()<br>        <span class="hljs-keyword">and</span> device == <span class="hljs-string">&quot;cpu&quot;</span><br>    ):<br>        device = <span class="hljs-string">&quot;mps&quot;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> device:<br>        device = <span class="hljs-string">&quot;cuda&quot;</span><br>    <span class="hljs-keyword">if</span> device <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> models.keys():<br>        models[device] = DebertaV2Model.from_pretrained(LOCAL_PATH).to(device)<br>    <span class="hljs-keyword">with</span> torch.no_grad():<br>        inputs = tokenizer(text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> inputs:<br>            inputs[i] = inputs[i].to(device)<br>        res = models[device](**inputs, output_hidden_states=<span class="hljs-literal">True</span>)<br>        res = torch.cat(res[<span class="hljs-string">&quot;hidden_states&quot;</span>][-<span class="hljs-number">3</span>:-<span class="hljs-number">2</span>], -<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].cpu()<br>        <span class="hljs-keyword">if</span> style_text:<br>            style_inputs = tokenizer(style_text, return_tensors=<span class="hljs-string">&quot;pt&quot;</span>)<br>            <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> style_inputs:<br>                style_inputs[i] = style_inputs[i].to(device)<br>            style_res = models[device](**style_inputs, output_hidden_states=<span class="hljs-literal">True</span>)<br>            style_res = torch.cat(style_res[<span class="hljs-string">&quot;hidden_states&quot;</span>][-<span class="hljs-number">3</span>:-<span class="hljs-number">2</span>], -<span class="hljs-number">1</span>)[<span class="hljs-number">0</span>].cpu()<br>            style_res_mean = style_res.mean(<span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">assert</span> <span class="hljs-built_in">len</span>(word2ph) == res.shape[<span class="hljs-number">0</span>], (text, res.shape[<span class="hljs-number">0</span>], <span class="hljs-built_in">len</span>(word2ph))<br>    word2phone = word2ph<br>    phone_level_feature = []<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(word2phone)):<br>        <span class="hljs-keyword">if</span> style_text:<br>            repeat_feature = (<br>                res[i].repeat(word2phone[i], <span class="hljs-number">1</span>) * (<span class="hljs-number">1</span> - style_weight)<br>                + style_res_mean.repeat(word2phone[i], <span class="hljs-number">1</span>) * style_weight<br>            )<br>        <span class="hljs-keyword">else</span>:<br>            repeat_feature = res[i].repeat(word2phone[i], <span class="hljs-number">1</span>)<br>        phone_level_feature.append(repeat_feature)<br><br>    phone_level_feature = torch.cat(phone_level_feature, dim=<span class="hljs-number">0</span>)<br><br>    <span class="hljs-keyword">return</span> phone_level_feature.T<br></code></pre></td></tr></table></figure>

<h2 id="TextEncoder"><a href="#TextEncoder" class="headerlink" title="TextEncoder"></a>TextEncoder</h2><p>The input data for the TextEncoder network of BERT-VITS2 has been augmented with BERT features.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">TextEncoder</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params"></span><br><span class="hljs-params">        self,</span><br><span class="hljs-params">        n_vocab,</span><br><span class="hljs-params">        out_channels,</span><br><span class="hljs-params">        hidden_channels,</span><br><span class="hljs-params">        filter_channels,</span><br><span class="hljs-params">        n_heads,</span><br><span class="hljs-params">        n_layers,</span><br><span class="hljs-params">        kernel_size,</span><br><span class="hljs-params">        p_dropout,</span><br><span class="hljs-params">        gin_channels=<span class="hljs-number">0</span>,</span><br><span class="hljs-params">    </span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        self.n_vocab = n_vocab<br>        self.out_channels = out_channels<br>        self.hidden_channels = hidden_channels<br>        self.filter_channels = filter_channels<br>        self.n_heads = n_heads<br>        self.n_layers = n_layers<br>        self.kernel_size = kernel_size<br>        self.p_dropout = p_dropout<br>        self.gin_channels = gin_channels<br>        self.emb = nn.Embedding(<span class="hljs-built_in">len</span>(symbols), hidden_channels)<br>        nn.init.normal_(self.emb.weight, <span class="hljs-number">0.0</span>, hidden_channels**-<span class="hljs-number">0.5</span>)<br>        self.tone_emb = nn.Embedding(num_tones, hidden_channels)<br>        nn.init.normal_(self.tone_emb.weight, <span class="hljs-number">0.0</span>, hidden_channels**-<span class="hljs-number">0.5</span>)<br>        self.language_emb = nn.Embedding(num_languages, hidden_channels)<br>        nn.init.normal_(self.language_emb.weight, <span class="hljs-number">0.0</span>, hidden_channels**-<span class="hljs-number">0.5</span>)<br>        self.bert_proj = nn.Conv1d(<span class="hljs-number">1024</span>, hidden_channels, <span class="hljs-number">1</span>)<br><br>        <span class="hljs-comment"># Remove emo_vq since it&#x27;s not working well.</span><br>        self.style_proj = nn.Linear(<span class="hljs-number">256</span>, hidden_channels)<br><br>        self.encoder = attentions.Encoder(<br>            hidden_channels,<br>            filter_channels,<br>            n_heads,<br>            n_layers,<br>            kernel_size,<br>            p_dropout,<br>            gin_channels=self.gin_channels,<br>        )<br>        self.proj = nn.Conv1d(hidden_channels, out_channels * <span class="hljs-number">2</span>, <span class="hljs-number">1</span>)<br></code></pre></td></tr></table></figure>

<h1 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h1><p>The rough processing flow of VITS (Voice Inference from Text Sequences) is as follows:</p>
<ul>
<li>TextEncoder receives input text sequences of shape [1, len], obtains embeddings and transposes them to shape [1, 192, len].<br>The text sequences are encoded using transformer structures, resulting in encoded representations of shape [1, 192, len].</li>
<li>The Speaker Diarization Predictor (SDP) predicts the length information for each text sequence, resulting in predictions of shape [1, 1, len]. The specific length values are summed to obtain the total length (ALen).</li>
<li>The text sequence data of shape [1, 192, len] is multiplied to obtain phoneme data of shape [1, 192, ALen].</li>
<li>The Residual Coupling Block is applied to transform the latent variable x into z with the desired distribution.</li>
<li>The Decoder generates audio data by upsampling the input from [1, 192, ALen] to [1, 96, ALen2] to [1, 48, ALen4]… to [1, 1, wav_len], resulting in the generated audio data.</li>
<li>The short audio results generated from the short text sequences are concatenated with intervals inserted in between.</li>
</ul>
<p>VITS2 builds upon VITS1 with optimizations.<br>BERT-VITS2, based on VITS2, introduces the bert_feature input in the TextEncoder network. The network extracts BERT features for each language, each of which is approximately 1.3GB. The main VITS network is around 700MB.</p>
<p>VITS-based models tend to receive short audio files as training data which could be splited and labeled with the following codes:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># speech_to_text.py</span><br><span class="hljs-keyword">import</span> whisper <br><span class="hljs-keyword">import</span> os <br><span class="hljs-keyword">def</span> <span class="hljs-title function_">check_is_encode_error</span>(<span class="hljs-params">string:<span class="hljs-built_in">str</span></span>)-&gt; <span class="hljs-built_in">bool</span>:<br>    <span class="hljs-keyword">try</span>:<br>        string.encode(<span class="hljs-string">&#x27;gbk&#x27;</span>)<br>    <span class="hljs-keyword">except</span> UnicodeEncodeError:<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">True</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-literal">False</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">process</span>(<span class="hljs-params">file_path:<span class="hljs-built_in">str</span>, name:<span class="hljs-built_in">str</span>, <span class="hljs-built_in">id</span>:<span class="hljs-built_in">int</span></span>):<br>    g = os.walk(file_path)  <br>    voice = []<br>    <span class="hljs-keyword">for</span> path,dir_list,file_list <span class="hljs-keyword">in</span> g:  <br>        <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> file_list:  <br>            voice.append(os.path.join(path, file_name))<br><br>    speaker_id = <span class="hljs-built_in">str</span>(<span class="hljs-built_in">id</span>)<br>    contents = []<br>    model = whisper.load_model(<span class="hljs-string">&quot;base&quot;</span>)<br>    <span class="hljs-keyword">for</span> sub <span class="hljs-keyword">in</span> voice:<br>        <span class="hljs-keyword">try</span>:<br>            result = model.transcribe(sub)<br>        <span class="hljs-keyword">except</span>:<br>            <span class="hljs-keyword">continue</span><br>        <span class="hljs-keyword">if</span> check_is_encode_error(result[<span class="hljs-string">&quot;text&quot;</span>]):<br>            <span class="hljs-keyword">continue</span><br>        <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(result[<span class="hljs-string">&quot;text&quot;</span>]) &lt; <span class="hljs-number">10</span>:<br>            <span class="hljs-keyword">continue</span><br>        <span class="hljs-comment">#temp = sub + &#x27;|&#x27; + speaker_id + &#x27;|&#x27; + result[&quot;text&quot;] + &quot;\n&quot;</span><br>        temp = sub + <span class="hljs-string">&#x27;|&#x27;</span> + <span class="hljs-string">&#x27;model31216&#x27;</span> + <span class="hljs-string">&#x27;|&#x27;</span> + <span class="hljs-string">&#x27;JP&#x27;</span> + <span class="hljs-string">&#x27;|&#x27;</span> + result[<span class="hljs-string">&quot;text&quot;</span>] + <span class="hljs-string">&quot;\n&quot;</span><br>        lab_path = sub.split(<span class="hljs-string">&#x27;.&#x27;</span>)[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;.lab&#x27;</span><br>        <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(lab_path, <span class="hljs-string">&#x27;w&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>            f.write(result[<span class="hljs-string">&quot;text&quot;</span>])<br>        f.close<br>        <span class="hljs-built_in">print</span>(temp)<br>        contents.append(temp)<br>    <br>    length = <span class="hljs-built_in">len</span>(contents)<br>    train_len = <span class="hljs-built_in">int</span>(length*<span class="hljs-number">0.9</span>)<br>    train_contents = contents[:train_len]<br>    val_contents = contents[train_len:]<br>    train_path = <span class="hljs-string">&quot;path&quot;</span> + <span class="hljs-string">&quot;&#123;&#125;_train.txt&quot;</span>.<span class="hljs-built_in">format</span>(name)<br>    val_path = <span class="hljs-string">&quot;path&quot;</span> + <span class="hljs-string">&quot;&#123;&#125;_val.txt&quot;</span>.<span class="hljs-built_in">format</span>(name)<br>    f=<span class="hljs-built_in">open</span>(train_path, <span class="hljs-string">&quot;w&quot;</span>)<br>    f.writelines(train_contents)<br>    f.close()<br>    f=<span class="hljs-built_in">open</span>(val_path, <span class="hljs-string">&quot;w&quot;</span>)<br>    f.writelines(val_contents)<br>    f.close()<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># sep.py</span><br><span class="hljs-keyword">from</span> pydub <span class="hljs-keyword">import</span> AudioSegment<br><span class="hljs-keyword">from</span> pydub.utils <span class="hljs-keyword">import</span> make_chunks<br><span class="hljs-keyword">from</span> scipy.io.wavfile <span class="hljs-keyword">import</span> write<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">resample_audio</span>(<span class="hljs-params">audio:AudioSegment, output_file:<span class="hljs-built_in">str</span>, target_sample_rate=<span class="hljs-number">22050</span></span>):<br><br>    <span class="hljs-comment"># Resample the audio to the target sample rate using pydub</span><br>    audio = audio.set_channels(<span class="hljs-number">1</span>)  <span class="hljs-comment"># Ensure mono</span><br>    audio = audio.set_frame_rate(target_sample_rate)<br><br>    <span class="hljs-comment"># Export the resampled audio as a 16-bit WAV file</span><br>    audio.export(output_file, <span class="hljs-built_in">format</span>=<span class="hljs-string">&quot;wav&quot;</span>, codec=<span class="hljs-string">&quot;pcm_s16le&quot;</span>)<br></code></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-comment"># main.py</span><br><span class="hljs-keyword">from</span> sep <span class="hljs-keyword">import</span> resample_audio<br><span class="hljs-keyword">from</span> speech_to_text <span class="hljs-keyword">import</span> process<br><span class="hljs-keyword">import</span> argparse<br><span class="hljs-keyword">from</span> pydub <span class="hljs-keyword">import</span> AudioSegment<br><span class="hljs-keyword">from</span> pydub.utils <span class="hljs-keyword">import</span> make_chunks<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> logging<br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&#x27;__main__&#x27;</span>:<br>    parser = argparse.ArgumentParser()<br>    parser.add_argument(<span class="hljs-string">&quot;--name&quot;</span>, default=<span class="hljs-string">&quot;Shichan&quot;</span>)<br>    parser.add_argument(<span class="hljs-string">&quot;--id&quot;</span>, default=<span class="hljs-string">&quot;63&quot;</span>)<br>    args = parser.parse_args()<br><br>    voice_path = <span class="hljs-string">&quot;/home/denghao/pro/sasayaki/voice/&quot;</span> + args.name<br>    g = os.walk(voice_path)  <br>    voice = []<br>    <span class="hljs-keyword">for</span> path,dir_list,file_list <span class="hljs-keyword">in</span> g:  <br>        <span class="hljs-keyword">for</span> file_name <span class="hljs-keyword">in</span> file_list:  <br>            voice.append(os.path.join(path, file_name))<br><br>    logging.info(<span class="hljs-string">&quot;ボイスをロードしました。&quot;</span>)<br>    sep_path = <span class="hljs-string">&quot;/home/denghao/pro/Bert-VITS2/Data/model31216/audios/wavs/&quot;</span> <span class="hljs-comment">#+  args.name + &#x27;/&#x27;</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> os.path.exists(sep_path):<br>        os.makedirs(sep_path)<br>    seq = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">for</span> file <span class="hljs-keyword">in</span> voice:<br>        <span class="hljs-built_in">type</span> = file.split(<span class="hljs-string">&#x27;.&#x27;</span>)[-<span class="hljs-number">1</span>]<br>        audio = AudioSegment.from_file(file, <span class="hljs-built_in">type</span>)<br><br>        size = <span class="hljs-number">3500</span><br><br>        chunks = make_chunks(audio, size)<br><br>        <span class="hljs-keyword">for</span> i, chunk <span class="hljs-keyword">in</span> <span class="hljs-built_in">enumerate</span>(chunks):<br>            j = i+seq<br>            chunk_name = sep_path + args.name + <span class="hljs-string">&#x27;-&#123;0&#125;.wav&#x27;</span>.<span class="hljs-built_in">format</span>(j)<br>            <span class="hljs-comment">#chunk_name = &quot;/home/denghao/pro/vits-finetuning-main/wav/vtb/akane/anko-&#123;0&#125;.wav&quot;.format(j)</span><br>            <span class="hljs-built_in">print</span>(chunk_name)<br>            resample_audio(chunk, chunk_name)<br>        seq += i<br>    logging.info(<span class="hljs-string">&quot;文字転換を始める。&quot;</span>)<br>    process(sep_path, args.name, args.<span class="hljs-built_in">id</span>)<br>    logging.info(<span class="hljs-string">&quot;処理完了。&quot;</span>)<br></code></pre></td></tr></table></figure>
      </section>
      <section class="extra">
        
          
        
        
        
        
  <nav class="nav">
    <a href="/2023/12/30/AI-Agent/"><i class="iconfont iconleft"></i>Overview of AI Agent</a>
    <a href="/2023/09/22/selve/">😊<i class="iconfont iconright"></i></a>
  </nav>

      </section>
      
    </section>
  </div>
</article></div>
      <div class="col-xl-3">
        
          
  <aside class="toc-wrap">
    <h3 class="toc-title">Index</h3>
    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Introduction"><span class="toc-text">Introduction</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Method"><span class="toc-text">Method</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Stochastic-Duration-Predictor-with-Time-Step-wise-Conditional-Discriminator"><span class="toc-text">Stochastic Duration Predictor with Time Step-wise Conditional Discriminator</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Monotonic-Alignment-Search-with-Gaussian-Noise"><span class="toc-text">Monotonic Alignment Search with Gaussian Noise</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Normalizing-Flows-using-Transformer-Block"><span class="toc-text">Normalizing Flows using Transformer Block</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Speaker-Conditioned-Text-Encoder"><span class="toc-text">Speaker-Conditioned Text Encoder</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Bert-VITS2"><span class="toc-text">Bert-VITS2</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Segmentation"><span class="toc-text">Segmentation</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Tone-encoding"><span class="toc-text">Tone encoding</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Extracting-BERT-features-from-text-data"><span class="toc-text">Extracting BERT features from text data</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#TextEncoder"><span class="toc-text">TextEncoder</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Summary"><span class="toc-text">Summary</span></a></li></ol>
  </aside>

        
      </div>
    </div>
  </div>
</main>
  

  <footer class="footer">
    <div class="footer-social"><a href="mailto:Avidya@ieee.org " target="_blank"
  class="footer-social-item" onMouseOver="this.style.color=#FF3B00"
  onMouseOut="this.style.color='#33333D'">
  <i class="iconfont  iconmail"></i>
  </a></div>
    
  </footer>
  
      <div class="fab fab-plus">
    <i class="iconfont iconplus"></i>
  </div>
  
  
  
  <div class="fab fab-up">
    <i class="iconfont iconcaret-up"></i>
  </div>
  
  
  
    
<script src="/js/color-mode.js"></script>

  
  
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>

<script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>





  
<script src="https://cdn.bootcdn.net/ajax/libs/jquery.lazyload/1.9.1/jquery.lazyload.min.js"></script>




  
<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js"></script>








<script src="/js/utils.js"></script>
<script src="/js/script.js"></script>







  <script>
    (function () {
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
      } else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
      }
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>












</html>